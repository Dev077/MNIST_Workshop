{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3a065d04-46a3-4bac-9ab3-fa176c78886d",
      "metadata": {
        "id": "3a065d04-46a3-4bac-9ab3-fa176c78886d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21cbf905-e151-4580-e753-b2b4b00067a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MNIST WORKSHOP WORKBOOK'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"MNIST WORKSHOP WORKBOOK\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2869b55b-5bf5-414a-aa2a-d459da73eb04",
      "metadata": {
        "id": "2869b55b-5bf5-414a-aa2a-d459da73eb04"
      },
      "outputs": [],
      "source": [
        "import torch as pt\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7890b7c8-30dc-4aa0-b2fd-e0fe46c247cf",
      "metadata": {
        "id": "7890b7c8-30dc-4aa0-b2fd-e0fe46c247cf"
      },
      "outputs": [],
      "source": [
        "#Part1: The Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e16eb1d-4eb8-489b-805b-13e6bb73e04e",
      "metadata": {
        "id": "1e16eb1d-4eb8-489b-805b-13e6bb73e04e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A perceptron is the simplest form of a neural network. It performs the following computation:\n",
        "\n",
        "   y = σ(x @ w.T + b)\n",
        "\n",
        "Where:\n",
        "x: input vector (batch_size, input_features)\n",
        "w: weight matrix (output_features, input_features)\n",
        "b: bias vector (output_features)\n",
        "σ: activation function (sigmoid in our case)\n",
        "@: matrix multiplication\n",
        "y: output vector (batch_size, output_features)\n",
        "\n",
        "The sigmoid activation function σ(z) = 1 / (1 + exp(-z)) squashes values to (0, 1).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9cbc078d-2999-491a-a293-dc3bdc8f71e2",
      "metadata": {
        "id": "9cbc078d-2999-491a-a293-dc3bdc8f71e2"
      },
      "outputs": [],
      "source": [
        "sigmoid = nn.Sigmoid() # initialise the sigmoid function\n",
        "\n",
        "# 1.1: Write a function \"perceptron\" that performs a single perceptron step.\n",
        "\"\"\"\n",
        "The function must accept three arguments: x (inputs), w (weights), and b (bias).\n",
        "1. Calculate the linear step, z=xW^T +b.\n",
        "Hint: You'll need to use matrix multiplication (@) and the transpose (.T) of the weights.\n",
        "2. Apply the global sigmoid activation function to z.\n",
        "3. Return the final activated output.\n",
        "\"\"\"\n",
        "#Code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "1db96396-acb9-4c04-8919-49504c63f944",
      "metadata": {
        "id": "1db96396-acb9-4c04-8919-49504c63f944"
      },
      "outputs": [],
      "source": [
        "# Let's train a perceptron to learn logical operations\n",
        "\n",
        "x = pt.tensor([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "], dtype=pt.float32)\n",
        "\n",
        "y = pt.tensor([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "], dtype=pt.float32)\n",
        "\n",
        "# Initialize weights: (1 output neuron, 2 input features).\n",
        "# nn.Parameter tells PyTorch this tensor is learnable (track gradients).\n",
        "w_or = nn.Parameter(pt.randn(1, 2))\n",
        "b_or = nn.Parameter(pt.randn(1)) # Initialize bias: (1 bias value for the 1 output neuron).This is also a learnable parameter.\n",
        "\n",
        "# Optimiser is responsible for updating our learnable parameters [w_or, b_or]. lr=1.0 is the learning rate, controlling the size of the update step.\n",
        "optimizer = optim.SGD([w_or, b_or], lr=1.0)\n",
        "\n",
        "# The lose function measures the average squared difference between our model's prediction and the correct answer (y_or).\n",
        "criterion = nn.MSELoss() # Mean Squared Error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "id": "c2b429d1-546e-43a3-be31-48b96a647bef",
      "metadata": {
        "id": "c2b429d1-546e-43a3-be31-48b96a647bef"
      },
      "outputs": [],
      "source": [
        "# 1.2: Write the training loop to teach the perceptron the \"OR\" gate:\n",
        "\"\"\"\n",
        "1. Create a for loop that runs for 10 epochs.\n",
        "2. Inside the loop, implement the 5 core steps of training:\n",
        "    a.Forward Pass: Get predictions from your perceptron function.\n",
        "    b.Calculate Loss: Use the criterion to compare your predictions with y_or.\n",
        "    c.Zero Gradients: Call optimizer.zero_grad().\n",
        "    d.Backward Pass: Call .backward() on your loss.\n",
        "    e.Update Weights: Call optimizer.step().\n",
        "3. Add logic to print the loss every 10 epochs.\n",
        "\"\"\"\n",
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "id": "6a232838-5ee7-45ad-a7e6-033a3c387c64",
      "metadata": {
        "id": "6a232838-5ee7-45ad-a7e6-033a3c387c64"
      },
      "outputs": [],
      "source": [
        "# --- Visualization Checkpoint ---\n",
        "\"\"\"\n",
        "This is your visualization cell. Run this cell once to see the model's (random) initial predictions.\n",
        "After you complete Task 1.3, you will run this cell again every time you run the training cell to see your model learn!\n",
        "\"\"\"\n",
        "plt.imshow(x.T, vmin=0)\n",
        "plt.title(\"Inputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(y.T, vmin=0)\n",
        "plt.title(\"Target Outputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(pred.detach().T, vmin=0)\n",
        "plt.title(\"Model Outputs\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Parameters:\\n\\tWeights: {w_or.detach()}\\n\\tBias: {b_or.detach()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "74b1ddd8-8fb8-4fe5-91e2-1cff82b08490",
      "metadata": {
        "id": "74b1ddd8-8fb8-4fe5-91e2-1cff82b08490"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Let's try XOR gate, after this try visualizing and then run the\n",
        "[gradient descent cell] to your heart's content.\n",
        "Observe how effectively the model can learn the XOR gate.\n",
        "\"\"\"\n",
        "x = pt.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=pt.float32)\n",
        "y = pt.tensor([[0], [1], [1], [0]], dtype=pt.float32)\n",
        "w_xor = nn.Parameter(pt.randn(1, 2))\n",
        "b_xor = nn.Parameter(pt.randn(1))\n",
        "optimizer = optim.SGD([w_xor, b_xor], lr=1.0)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "id": "11112c86-fc88-44bc-a957-64dbbe6fb5b1",
      "metadata": {
        "id": "11112c86-fc88-44bc-a957-64dbbe6fb5b1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Write a new training loop for the XOR data.\n",
        "1. Create a for loop that runs for 1000 epochs.\n",
        "2. Implement the same 5 core steps of training as before, but using the x_xor and y_xor data.\n",
        "3. Print the loss every 100 epochs.\n",
        "4. Run the visualisation step\n",
        "\"\"\"\n",
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02212bf4-b4b7-4cb6-befb-5d7607e8ca25",
      "metadata": {
        "id": "02212bf4-b4b7-4cb6-befb-5d7607e8ca25"
      },
      "outputs": [],
      "source": [
        "# Part2: Multi-Layer-Perceptron(MCP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4635690-7e58-4190-8e90-8127e76ac487",
      "metadata": {
        "id": "f4635690-7e58-4190-8e90-8127e76ac487"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "To solve non-linear problems like XOR, we can stack perceptrons into layers.\n",
        "The output of one layer becomes the input to the next. This is an MLP\n",
        "Input -> Perceptron Layer 1 (Hidden) -> Perceptron Layer 2 (Output)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "id": "b3b62398-d994-47f8-aada-4e4c5c824961",
      "metadata": {
        "id": "b3b62398-d994-47f8-aada-4e4c5c824961"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "let's start with 2-layer perceptron\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "id": "9e4982ab-3ad6-48c7-95a5-3f4512d6faf1",
      "metadata": {
        "id": "9e4982ab-3ad6-48c7-95a5-3f4512d6faf1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "2.1: Write a function mlp that uses your perceptron function twice.\n",
        "\n",
        "1. The function should accept one argument: x (the input).\n",
        "2. You will need to define the following parameters outside the function.\n",
        "    a. w_1, b_1: For a hidden layer with 2 inputs and 2 neurons.\n",
        "    b. w_2, b_2: For an output layer with 2 inputs and 1 neuron.\n",
        "    c. optimiser for all the above defined parameters\n",
        "    d. calling loss function\n",
        "5. Inside the function:\n",
        "    a. Pass x through the first perceptron (w_1, b_1) to get y_1.\n",
        "    b. Pass y_1 through the second perceptron (w_2, b_2) to get the final output.\n",
        "    c. Return the final output.\n",
        "\"\"\"\n",
        "w_1 = None  # YOUR CODE HERE - shape (2, 2) - input to hidden\n",
        "b_1 = None  # YOUR CODE HERE - shape (2,) - hidden bias\n",
        "w_2 = None  # YOUR CODE HERE - shape (1, 2) - hidden to output\n",
        "b_2 = None  # YOUR CODE HERE - shape (1,) - output bias\n",
        "\n",
        "#Create optimizer for all parameters\n",
        "optimizer_mlp = None  # YOUR CODE HERE - SGD with lr=1, parameters=[w_1, b_1, w_2, b_2]\n",
        "\n",
        "def mlp(x, w_1, b_1, w_2, b_2):\n",
        "  #code here\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "id": "554b69a2-fdff-4436-aeb4-c4f0f1b978f7",
      "metadata": {
        "id": "554b69a2-fdff-4436-aeb4-c4f0f1b978f7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "2.2: Write the training loop for the MLP\n",
        "\n",
        "1. A for loop for 1000 epochs.\n",
        "    a. The 5 training steps, this time using your mlp(x_xor) function and y_xor.\n",
        "    b. Print the loss every 100 epochs.\n",
        "\"\"\"\n",
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "id": "9a3ed718-9cd0-406c-96c5-c3d78d6befea",
      "metadata": {
        "id": "9a3ed718-9cd0-406c-96c5-c3d78d6befea"
      },
      "outputs": [],
      "source": [
        "#Check your answer\n",
        "\"\"\"\n",
        "This is your visualization cell. Run this cell once to see the model's (random) initial predictions.\n",
        "After you complete Task 1.3, you will run this cell again every time you run the training cell to see your model learn!\n",
        "\"\"\"\n",
        "plt.imshow(x.T, vmin=0)\n",
        "plt.title(\"Inputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(y.T, vmin=0)\n",
        "plt.title(\"Target Outputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(pred.detach().T, vmin=0)\n",
        "plt.title(\"Model Outputs\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Parameters:\\n\\tWeights: {w_or.detach()}\\n\\tBias: {b_or.detach()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b654c3-f9e1-4a4c-8f2d-6fd02aca7cf6",
      "metadata": {
        "id": "c3b654c3-f9e1-4a4c-8f2d-6fd02aca7cf6"
      },
      "outputs": [],
      "source": [
        "#Part 3: A Practical MLP for Image Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3debfcf4-adbd-4f52-a3cc-b244cb3e15d1",
      "metadata": {
        "id": "3debfcf4-adbd-4f52-a3cc-b244cb3e15d1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Manually managing weights is tedious. PyTorch makes this easy with the nn.Module class.\n",
        "Let's build an actual MLP to recognize handwritten digits from the MNIST dataset.\n",
        "\"\"\"\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "transform = ToTensor()\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(\"Training dataset size:\", len(train_dataset))\n",
        "print(\"Test dataset size:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53978191-674e-43ac-8c81-3dabf7c13efc",
      "metadata": {
        "id": "53978191-674e-43ac-8c81-3dabf7c13efc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "3.1: Build an MLP class that inherits from nn.Module.\n",
        "1. In the __init__ method:\n",
        "    a. Call super().__init__().\n",
        "    b. Define a linear layer (nn.Linear) from 784 inputs (28*28) to 128 hidden neurons.\n",
        "    c. Define a nn.ReLU activation function.\n",
        "    d. Define a second linear layer from 128 inputs to 10 outputs (for digits 0-9).\n",
        "\n",
        "2. In the forward method:\n",
        "    a. The input x will have shape (batch_size, 1, 28, 28).\n",
        "    b. First, flatten the image. (Hint: x = x.reshape(x.size(0), -1)).\n",
        "    c. Pass x through your first linear layer.\n",
        "    d. Pass the result through the ReLU activation.\n",
        "    e. Pass the result through your second linear layer.\n",
        "    f. Return the final output.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "id": "773746e7-e0db-40d4-8c02-a818e3bb3482",
      "metadata": {
        "id": "773746e7-e0db-40d4-8c02-a818e3bb3482"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        # YOUR CODE HERE\n",
        "        # (Call super and define your 3 layers)\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE\n",
        "        # (Implement the 4 forward-pass steps)\n",
        "        pass\n",
        "\n",
        "model = MLP()\n",
        "print(model)\n",
        "\n",
        "# For multi-class classification, this is the standard loss function.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea7aae9-9dd0-44f6-a436-e794b4e1f241",
      "metadata": {
        "id": "3ea7aae9-9dd0-44f6-a436-e794b4e1f241"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "3.2: Write the full training loop for the MNIST dataset.\n",
        "1. Create a for loop that runs for 3 epochs.\n",
        "2. Inside that, create a nested for loop that iterates over the train_dataloader (this will give you images and labels).\n",
        "3. Inside the inner loop, perform the 5 training steps (Forward, Loss, Zero, Backward, Step).\n",
        "4. Add a print statement inside the inner loop to show progress (e.g., every 100 steps).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "7488c820-ac55-482c-8f67-edf0f5c73eb2",
      "metadata": {
        "id": "7488c820-ac55-482c-8f67-edf0f5c73eb2"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "num_epochs = 3\n",
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "989422da-b33e-4ac8-947e-8539b72d2aa9",
      "metadata": {
        "id": "989422da-b33e-4ac8-947e-8539b72d2aa9"
      },
      "outputs": [],
      "source": [
        "#Evaluate the Model you just trained\n",
        "model.eval()\n",
        "\n",
        "with pt.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "        outputs = model(images)\n",
        "        predicted = pt.argmax(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the {total} test images: {100 * correct / total:.4f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "126d5a08-bdef-4ac2-9e88-1caad5d61f02",
      "metadata": {
        "id": "126d5a08-bdef-4ac2-9e88-1caad5d61f02"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "data_iter = iter(test_dataloader)\n",
        "images, labels = next(data_iter)\n",
        "images_to_show = images[:5]\n",
        "labels_to_show = labels[:5]\n",
        "\n",
        "with pt.no_grad():\n",
        "    outputs = model(images_to_show)\n",
        "\n",
        "_, predicted = pt.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "print(\"Showing 5 test images and their predictions...\")\n",
        "for i in range(5):\n",
        "    plt.imshow(images_to_show[i][0], cmap='gray') # [i][0] to get the 2D image\n",
        "    plt.title(f\"Predicted: {predicted[i].item()}, Actual: {labels_to_show[i].item()}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e496a4-30d4-4a88-8e19-31ebedc53fe8",
      "metadata": {
        "id": "32e496a4-30d4-4a88-8e19-31ebedc53fe8"
      },
      "outputs": [],
      "source": [
        "#Part-4:CONVOLUTIONAL NEURAL NETWORKS (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb08604-8c49-4822-a232-f8675c517ba8",
      "metadata": {
        "id": "ccb08604-8c49-4822-a232-f8675c517ba8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MLPs treat images as flat vectors, losing spatial structure. CNNs use:\n",
        "\n",
        "1. CONVOLUTION: Detect local patterns (edges, corners) using small filters\n",
        "      - A 3x3 filter slides across the image\n",
        "      - Computes weighted sum at each position\n",
        "      - Learns filters through backpropagation\n",
        "\n",
        "2. POOLING: Reduce spatial dimensions while retaining important features\n",
        "   - Downsamples feature maps\n",
        "   - Provides translation invariance\n",
        "   - Reduces computation\n",
        "\n",
        "Architecture we'll build:\n",
        "Input (28x28x1)\n",
        "  -> Conv(16 filters, 3x3) + ReLU + AvgPool(2x2)\n",
        "  -> Conv(32 filters, 3x3) + ReLU + AvgPool(2x2)\n",
        "  -> Flatten\n",
        "  -> Linear(10)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "19d0433a-def5-4642-a145-9564bcdd390e",
      "metadata": {
        "id": "19d0433a-def5-4642-a145-9564bcdd390e"
      },
      "outputs": [],
      "source": [
        "# --- Setup for CNNS\n",
        "# This cell provides all the imports and data you'll need for this part of the workshop\n",
        "import torch as pt\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "transform = ToTensor()\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(\"Training dataset size:\", len(train_dataset))\n",
        "print(\"Test dataset size:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "4c065339-de51-4b6f-9ee8-27e010fff256",
      "metadata": {
        "id": "4c065339-de51-4b6f-9ee8-27e010fff256"
      },
      "outputs": [],
      "source": [
        "#4.1: grab one image from the train_dataset and visualize it.\n",
        "\n",
        "img, label = train_dataset[1]\n",
        "print(f\"Label: {label}\")\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.title(f\"Image of digit: {label}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "id": "ae85b96f-b59b-47a7-b5ed-bb47ba99424c",
      "metadata": {
        "id": "ae85b96f-b59b-47a7-b5ed-bb47ba99424c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4.2: Define and visualize a 3x3 vertical edge detector kernel.\n",
        "\n",
        "- A \"kernel\" is just a small matrix that acts as a feature detector. We'll create one that detects vertical edges.\n",
        "\n",
        "1. Define a variable kernel as a pt.tensor with dtype=pt.float32.\n",
        "2. The tensor's values should be: [[1, 0, -1], [1, 0, -1], [1, 0, -1]].\n",
        "3. Use plt.imshow(kernel) and plt.show() to see what it looks like.\n",
        "\"\"\"\n",
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e7e95ef-a071-44b0-a052-2997803fdf29",
      "metadata": {
        "id": "9e7e95ef-a071-44b0-a052-2997803fdf29"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4.3: Apply your kernel to one 3x3 patch of the image and visualize each step.\n",
        "\n",
        "1. Define a location: i, j = 16, 5.\n",
        "2. Extract the 3x3 patch from img[0] at that location.\n",
        "Hint: patch = img[0, i:i+3, j:j+3]\n",
        "\n",
        "3. Visualization 1: Use plt.imshow(patch, cmap=\"gray\") and plt.show() to see the raw patch.\n",
        "4. Visualization 2: Show the result of the element-wise multiplication.\n",
        "Hint: plt.imshow(patch * kernel, vmin=0, vmax=1) and plt.show().\n",
        "\n",
        "5. Visualization 3: Show the final summed value. This single number is the output of the convolution for this one pixel.\n",
        "Hint: plt.imshow(pt.sum(patch * kernel)[None, None], vmin=0, vmax=1) and plt.show().\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "id": "918e01c5-fddc-4c67-9a05-ee2097509416",
      "metadata": {
        "id": "918e01c5-fddc-4c67-9a05-ee2097509416"
      },
      "outputs": [],
      "source": [
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4105e6c2-7502-4a6a-93c6-991938152b63",
      "metadata": {
        "id": "4105e6c2-7502-4a6a-93c6-991938152b63"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4.4: Write the nested loops to perform a full convolution.\n",
        "\n",
        "1. A 28x28 image convolved with a 3x3 kernel (with no padding) results in a 26x26 feature map.\n",
        "   Create an empty tensor of this size: feature_map = pt.zeros(26, 26).\n",
        "2. Write a for loop that iterates i from 0 to 25.\n",
        "3. Inside, write a nested for loop that iterates j from 0 to 25.\n",
        "4. Inside the nested loop:\n",
        "5. Get the 3x3 patch from img[0] at the (i, j) location.\n",
        "6. Calculate the convolved value by multiplying the patch and kernel and getting their sum().\n",
        "7. Store this value in your feature map at feature_map[i, j].\n",
        "\n",
        "-> Visualization: After the loops, plt.imshow(feature_map.numpy(), vmin=0, vmax=1) to see the result.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "id": "bfc21c89-d058-48f3-91a2-11b6fbd81f80",
      "metadata": {
        "id": "bfc21c89-d058-48f3-91a2-11b6fbd81f80"
      },
      "outputs": [],
      "source": [
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "id": "a47ea343-b8da-46df-b596-3542de8e35b3",
      "metadata": {
        "id": "a47ea343-b8da-46df-b596-3542de8e35b3"
      },
      "outputs": [],
      "source": [
        "#let's overlay our new \"edge map\" on top of the original image to see where the features were detected.\n",
        "\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.title(\"Original Image with Feature Map Overlay\")\n",
        "plt.imshow(feature_map, cmap='viridis', alpha=0.5, extent=[0, 26, 26, 0], vmin=0)\n",
        "plt.colorbar(label='Feature Map Value')\n",
        "plt.title(\"Original Image with Feature Map Overlay\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a58a39a-5334-40c1-8c3c-d980683cc069",
      "metadata": {
        "id": "5a58a39a-5334-40c1-8c3c-d980683cc069"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4.5: Define the CNN class using nn.Module\n",
        "1. In __init__:\n",
        "    a. Call super().__init__().\n",
        "    b. Define Conv Stack 1: nn.Conv2d (1 in, 16 out, kernel 3, pad 1), nn.ReLU(), nn.AvgPool2d (kernel 2, stride 2).\n",
        "    c. Define Conv Stack 2: nn.Conv2d (16 in, 32 out, kernel 3, pad 1), nn.ReLU(), nn.AvgPool2d (kernel 2, stride 2).\n",
        "    d. Define a final Linear Layer: nn.Linear (input 32 * 7 * 7, output 10).\n",
        "\n",
        "In forward(x):\n",
        "    a. Pass x through Stack 1 (Conv1 -> ReLU1 -> Pool1).\n",
        "    b. Pass the result through Stack 2 (Conv2 -> ReLU2 -> Pool2).\n",
        "    c. Flatten the output. (Hint: out = out.reshape(out.size(0), -1)).\n",
        "    d. Pass the flattened output through your final linear layer.\n",
        "    e. Return the result.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "id": "ee6226c7-d3fe-4965-939f-99d0b1a9b514",
      "metadata": {
        "id": "ee6226c7-d3fe-4965-939f-99d0b1a9b514"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        #CODE HERE\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "\n",
        "#Instantiate the model and print its details\n",
        "model = CNN()\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(model)\n",
        "print(f\"Total number of learnable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c097d586-27da-4339-ba3d-adb3f6480064",
      "metadata": {
        "id": "c097d586-27da-4339-ba3d-adb3f6480064"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4.6: Write the training loop for the MNIST dataset.\n",
        "    a. Create a for loop that runs for 3 epochs.\n",
        "    b. Create a nested for loop that iterates over the train_dataloader (getting images and labels).\n",
        "    c. Inside the inner loop, perform the 5 training steps (forward, loss, zero, backward, step).\n",
        "    d. Print the loss every 100 steps.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "id": "75277b67-7f2f-4a0a-af61-f726454283d0",
      "metadata": {
        "id": "75277b67-7f2f-4a0a-af61-f726454283d0"
      },
      "outputs": [],
      "source": [
        "#Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "id": "44794e97-00f8-4bbb-a23e-d94e015baec4",
      "metadata": {
        "id": "44794e97-00f8-4bbb-a23e-d94e015baec4"
      },
      "outputs": [],
      "source": [
        "# You've trained it! Let's see the accuracy. We've provided the evaluation code for you\n",
        "# Run this cell to see the accuracy of your trained CNN!\n",
        "\n",
        "print(\"Evaluating model on the test dataset...\")\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "cnn_model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with pt.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        # 1. Forward pass\n",
        "        outputs = cnn_model(images)\n",
        "\n",
        "        # 2. Get the predicted class\n",
        "        _, predicted = pt.max(outputs.data, 1)\n",
        "\n",
        "        # 3. Update totals\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate and print the final accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'\\nAccuracy of the CNN on the 10000 test images: {accuracy:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "id": "6a9e7b3c-a7e0-43c9-ad68-800932935901",
      "metadata": {
        "id": "6a9e7b3c-a7e0-43c9-ad68-800932935901"
      },
      "outputs": [],
      "source": [
        "# Run this cell to see your trained CNN in action!\n",
        "\n",
        "print(\"\\n--- Visualizing CNN Predictions ---\")\n",
        "\n",
        "# 1. Get one batch of test data\n",
        "data_iter = iter(test_dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# 2. Get the first 5 images\n",
        "images_to_show = images[:5]\n",
        "labels_to_show = labels[:5]\n",
        "\n",
        "# 3. Pass these 5 images through your trained cnn_model\n",
        "with pt.no_grad():\n",
        "    outputs = cnn_model(images_to_show)\n",
        "\n",
        "# 4. Get the predicted class index (the one with the highest score)\n",
        "_, predicted = pt.max(outputs.data, 1)\n",
        "\n",
        "# 5. Loop and plot\n",
        "print(\"Showing 5 test images and their predictions...\")\n",
        "for i in range(5):\n",
        "    # Set up the plot\n",
        "    # images_to_show[i][0] gets the i-th image and its 0-th channel (the grayscale data)\n",
        "    plt.imshow(images_to_show[i][0], cmap='gray')\n",
        "\n",
        "    # Set the title with the prediction and the true label\n",
        "    # .item() converts the tensor value to a plain Python number\n",
        "    plt.title(f\"Predicted: {predicted[i].item()}, Actual: {labels_to_show[i].item()}\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7179a1b-4a1c-4de4-8b99-937a178895a2",
      "metadata": {
        "id": "a7179a1b-4a1c-4de4-8b99-937a178895a2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "THE END\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}